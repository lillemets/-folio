---
title: "Propensity score matching with R"
bibliography: '/home/jrl/text/library.bib'
description: "A walkthrough on how to carry out PSM analysis in base R."
---

```{r setup, include = F, eval = T}
# Settings
knitr::opts_chunk$set(include = T, eval = T, message = F, warning = F, 
                      fig.asp = .5, fig.width = 10)
# Set working directory
knitr::opts_knit$set(root.dir = '/home/jrl/') 
```

In impact evalations it is often necessary to measure the effect of a treatment, be it a support measure, training program or some other action. To make unbiased conclusions about the true effect, it is then neccessary to take into account what would have happened without a treatment, i.e. evaluate a counterfactual situation. Subtracting the outcome of a control group from the result of treated observatons allows us to do just that but it is crucial to control for selection bias. Impact evaluations are usually carried out retrospectively and many treatments permit random assignment of invdividuals into treatment and control groups. Thus, experimental research design (most prominently randomized controlled trials) can not be employed in such cases and we need to adopt non- or quasi-experimental methods. In the latter case, a pseudo control group is created so that it accurately reflects the counterfactual situation. Perhaps the most popular method for this purpose is  propensity score matching (PSM). The propensity of each observation to be treated (i.e. propensity score) is assessed and then observatons with close values of this assessment are compared. This allows us to compare observations where treatment can be the only source of differences in outome, thus mitigating selection bias.

There are at least two R packages that help performing the matching, namely [MatchIt](https://cran.r-project.org/package=MatchIt) and [Matching](https://cran.r-project.org/package=Matching). However, I felt like taking a more hands-on approach.

# Data entry

In order to carry out PSM analysis we need a rather specific data set. Unfortunately, data that contains non-experimental treatment and control group as well as confounding variables predicting treatment and the outcome is rather hard to come by. Thus, we'll be using data set provided by @Lalonde1986 that includes the resuls of an employment and training program. This data set has previously been used by @Sekhon2011a to demonstrate some functions related to PSM. The data is available for treament and control group observations as separate tables. So we will load these tables and bind them into a data frame using only columnns that are present in both tables. The last variables contain earnings of individuals in respective years.

```{r}
treated <- read.table('http://users.nber.org/~rdehejia/data/nsw_treated.txt',
                      col.names = c('treated', 'age', 'education', 'black', 'hispanic', 'married',
                      'nodegree', 're75', 're78'))
control <- read.table('http://users.nber.org/~rdehejia/data/cps_controls.txt',
                      col.names = c('treated', 'age', 'education', 'black', 'hispanic', 'married',
                      'nodegree', 're74', 're75', 're78'))
lalonde <- rbind(treated[intersect(colnames(treated), colnames(control))],
                 control[intersect(colnames(treated), colnames(control))])
head(lalonde)
```

# The problem

We use `by` to get the summary of different variables separately for treated and other individuals.

```{r}
by(lalonde, lalonde$treated, summary)
```

It is evident that our initial control group is unbalanced since the distribution of the characteristics of individuals is very different. The change in median earnings for treated individuals between 1975 and 1978 is `r median(lalonde$re78[lalonde$treated == 1]) - median(lalonde$re75[lalonde$treated == 1])`. For others it is `r median(lalonde$re78[lalonde$treated == 0]) - median(lalonde$re75[lalonde$treated == 0])`. When adopting a "naive" approach we would assume that treatment increased medium earnings by the difference between the two values, i.e. `r (median(lalonde$re78[lalonde$treated == 1]) - median(lalonde$re75[lalonde$treated == 1])) - (median(lalonde$re78[lalonde$treated == 0]) - median(lalonde$re75[lalonde$treated == 0]))`. As treated individuals might have had a higher increase even without treatment, we would thus overestimate the effect of treatment by considering all of the individuals. It is thus necessary to create a balanced pseudo control group in order to simulate the counterfactual situation.

# Calculating propensity scores

Here we would like to assess the effect of treatment on earnings in 1978. We assume that age, years in education, race, marital status, academic degree and earnings in 1975 have an effect on both. So these need to be considered as confounding variabes and will be used to calulate the propensity score.

# Building a propensity score model

Since treatment status is indicated as a binary (dummy) variable, we will fit a logistic regression model on the data. Then we perform a stepwise regression that seeks to minimize the value of Akaike Information Criterion (AIC).

```{r}
prop.model <- glm(treated ~ age + education + black + hispanic + married + nodegree + re75, 
                  data = lalonde, family = binomial(link = "logit"))
step(prop.model)
```

According to AIC values, all of the variables improve the quality of the model. 

Next, we examine coefficients.

```{r}
summary(prop.model)
prop.model <- glm(treated ~ age + black + hispanic + married + nodegree + re75, 
                  data = lalonde, family = binomial(link = "logit"))
```

The coefficient of education is not significantly different from zero, so we updated our model not to include it. 

The dependent variable in logistic regression is binary and we can adjust the predicted values to describe binary outcome. too. Thus, we can draw a classificaion table that illustrates how well the model classifies the observations.

```{r}
table(prop.model$fitted.values > .5, lalonde$treated, dnn = c("Predicted", "True"))
```

The classification table indicates that the proportion of correctly classified treated observations is `r (table(prop.model$fitted.values > .5, lalonde$treated)[1] + table(prop.model$fitted.values > .5, lalonde$treated)[4]) / sum(table(prop.model$fitted.values > .5, lalonde$treated))`. This is a rather high rate.

We also calculate a few other statistics that help us evaluate a logistic regression model.

```{r eval = F}
# McFadden's pseudo R-squared value of the model
1 - (prop.model$deviance/prop.model$null.deviance)

# Test the model against a null model
pchisq(prop.model$null.deviance - prop.model$deviance, 
       prop.model$df.null - prop.model$df.residual, lower.tail = FALSE)
```

According to @McFadden1978, the value of McFadden's pseudo-R between 0.2 and 0.4 indicates an exellent model fit. The value we obtained is even higher. We can also reject the null hypothesis that all the coefficients in the model equal zero.

This model performs well enough on our data to use the fitted values of the dependent variable as propensity score values for each individual.

## Creating pseudo control group

Next we create a new variable and assign it propensity scores from the model. We can again use *by* to examine summary statistics of propensity scores separately for treated and other individuals. The comparison of two groups can also be plotted and adding some jitter gives a better overview.

```{r}
lalonde$propensity <- c(prop.model$fitted.values, use.names = F)
by(lalonde$propensity, lalonde$treated, summary)
plot(lalonde$propensity, jitter(lalonde$treated), 
     xlab = "Propensity score", ylab = "Treatment status")
```

As anticipated, the probability of treated observations to be treated is substantially higher.

There are various matching techniques that can be implemented to select appropriate individuals for control group, e.g. nearest-neighbour, kernel or caliper matching. Here we will use the latter as it allows us to set an acceptable range which functions as quality control [@Bryson2002, 27]. Standard deviation of the propensity score values of treated observations is adopted as the caliper. Every not treated individual whose propensity score is within the caliper of any treated individual's propensity score is placed in the control group. We will follow @Austin2011 who recommends using 0.2 standard deviations as the caliper width.

```{r include = F, eval = F}
# http://stackoverflow.com/a/43522373/6219179
CaliperMatching <- function(data, propensity, treated, caliper){
  cal <- caliper * sd(data$propensity[data$treated == 1])
  data$id <- row.names(data)
  f <- function(r) {
    x <- cut(data[r,]$propensity, 
             breaks = unique(c(data[!r,]$propensity - cal, data[!r,]$propensity + cal)))
    data[r,][!is.na(x),]$id
    }

data$group <- NA
data[data$id %in% f(data$treated==1),]$group <- "treated"
data[data$id %in% f(data$treated!=1),]$group <- "control"

data
}

lalonde.matched <- CaliperMatching(lalonde, propensity, treated, .2)
table(lalonde.matched[!is.na(lalonde.matched$group), 'group'])
plot(lalonde.matched$propensity, jitter(as.numeric(as.factor(lalonde.matched$group))))
```

# References

```{r include = F, eval = T}
# Save data
save.image('rsch/psm/data.RData')
```